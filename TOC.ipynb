{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOC of Ray End-to-End NLP Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
      "Processing /home/ubuntu/ray-e2e-nlp-example/transformers\n",
      "Requirement already satisfied: numpy in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.9.1) (1.16.4)\n",
      "Collecting tokenizers==0.7.0 (from transformers==2.9.1)\n",
      "  Using cached https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.9.1) (3.0.4)\n",
      "Requirement already satisfied: requests in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.9.1) (2.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.9.1) (4.38.0)\n",
      "Collecting regex!=2019.12.17 (from transformers==2.9.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1d/07/fb11080a1324bc8d7b68deb009a4c08bd675e0789a213028c58323c4aaab/regex-2020.5.14-cp36-cp36m-manylinux1_x86_64.whl (675kB)\n",
      "\u001b[K    100% |████████████████████████████████| 686kB 13.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece (from transformers==2.9.1)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 14.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting sacremoses (from transformers==2.9.1)\n",
      "Requirement already satisfied: dataclasses in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers==2.9.1) (0.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.9.1) (1.23)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.9.1) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.9.1) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers==2.9.1) (3.0.4)\n",
      "Requirement already satisfied: click in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.9.1) (6.7)\n",
      "Requirement already satisfied: six in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.9.1) (1.11.0)\n",
      "Requirement already satisfied: joblib in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers==2.9.1) (0.14.0)\n",
      "Building wheels for collected packages: transformers\n",
      "  Running setup.py bdist_wheel for transformers ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-_tg5af1w/wheels/6f/93/ec/cbeab5647367ce9297ec1668ff4829f8358872857a2de7ce89\n",
      "Successfully built transformers\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Installing collected packages: tokenizers, regex, sentencepiece, sacremoses, transformers\n",
      "Successfully installed regex-2020.5.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.9.1\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting tensorboard (from -r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/1d/fd/4f3ca1516cbb3713259ef229abd9314bba0077ef6070285dde0dd1ed21b2/tensorboard-2.2.1-py3-none-any.whl\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ./examples/requirements.txt (line 2)) (0.21.3)\n",
      "Collecting seqeval (from -r ./examples/requirements.txt (line 3))\n",
      "Requirement already satisfied: psutil in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from -r ./examples/requirements.txt (line 4)) (5.4.5)\n",
      "Collecting sacrebleu (from -r ./examples/requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl\n",
      "Collecting rouge-score (from -r ./examples/requirements.txt (line 6))\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
      "Collecting tensorflow_datasets (from -r ./examples/requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/bd/99/996b15ff5d11166c3516012838f569f78d57b71d4aac051caea826f6c7e0/tensorflow_datasets-3.1.0-py3-none-any.whl\n",
      "Collecting pytorch-lightning==0.7.3 (from -r ./examples/requirements.txt (line 8))\n",
      "  Using cached https://files.pythonhosted.org/packages/4e/53/0549dd9c44c90e96d217592e094e9c53ef39ae2fed0c5cdb7e57aca65af6/pytorch_lightning-0.7.3-py3-none-any.whl\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.14.1)\n",
      "Collecting markdown>=2.6.8 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a4/63/eaec2bd025ab48c754b55e8819af0f6a69e2b1e187611dd40cbbe101ee7f/Markdown-3.2.2-py3-none-any.whl\n",
      "Collecting absl-py>=0.4 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "Collecting google-auth<2,>=1.6.3 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/12/a3/2695fdcda305ea85c43ebd2a4d1429f3c7e897c7cf9045a8c378e1115a15/google_auth-1.15.0-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl\n",
      "Collecting setuptools>=41.0.0 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/c5/0d38afb961f83e0d51f319f7dc166195ebabc1ea3cb20a10a77f500f7156/setuptools-46.4.0-py3-none-any.whl (583kB)\n",
      "\u001b[K    100% |████████████████████████████████| 583kB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.16.4)\n",
      "Collecting grpcio>=1.24.3 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/23/62d3e82fa4c505f3195315c8a774b2e656b556d174329aa98edb829e48bc/grpcio-1.29.0.tar.gz (19.6MB)\n",
      "\u001b[K    100% |████████████████████████████████| 19.6MB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.11.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/51/cd/a0c1f9e4582ea64dddf76c1b808b318d01e3b858a51c715bffab1016ecc7/tensorboard_plugin_wit-1.6.0.post3-py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.31.1)\n",
      "Collecting protobuf>=3.6.0 (from tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c4/c1/300e675e55644f400b9e855c6a8189f3c9e4f41906a23954d15ebf59600f/protobuf-3.12.1-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.3MB 30.9MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (0.14.0)\n",
      "Collecting Keras>=2.2.4 (from seqeval->-r ./examples/requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/fd/6bfe87920d7f4fd475acd28500a42482b6b84479832bdc0fe9e589a60ceb/Keras-2.3.1-py2.py3-none-any.whl\n",
      "Collecting portalocker (from sacrebleu->-r ./examples/requirements.txt (line 5))\n",
      "  Using cached https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: typing in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacrebleu->-r ./examples/requirements.txt (line 5)) (3.6.4)\n",
      "Requirement already satisfied: nltk in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from rouge-score->-r ./examples/requirements.txt (line 6)) (3.3)\n",
      "Collecting termcolor (from tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "Requirement already satisfied: wrapt in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.10.11)\n",
      "Collecting future (from tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "Collecting dill (from tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "Requirement already satisfied: tqdm in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (4.38.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (18.1.0)\n",
      "Collecting promise (from tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "Collecting tensorflow-metadata (from tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "  Using cached https://files.pythonhosted.org/packages/33/13/ce395182239eb43f2e20c5ee81ce37fe65b481e95cb97b384a6e43d62317/tensorflow_metadata-0.22.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pytorch-lightning==0.7.3->-r ./examples/requirements.txt (line 8)) (1.3.1)\n",
      "Collecting importlib-metadata; python_version < \"3.8\" (from markdown>=2.6.8->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/ad/e4/891bfcaf868ccabc619942f27940c77a8a4b45fd8367098955bb7e152fb1/importlib_metadata-1.6.0-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4 (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<5.0,>=2.0.0 (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b3/59/524ffb454d05001e2be74c14745b485681c6ed5f2e625f71d135704c0909/cachetools-4.1.0-py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/95/de/214830a981892a3e286c3794f41ae67a4495df1108c3da8a9f62159b9a9d/pyasn1_modules-0.2.8-py2.py3-none-any.whl\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (1.23)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2019.9.11)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: h5py in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (2.8.0)\n",
      "Collecting keras-preprocessing>=1.0.5 (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/79/4c/7c3275a01e12ef9368a892926ab932b33bb13d55794881e3573482b378a7/Keras_Preprocessing-1.1.2-py2.py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.6 (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3))\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (3.12)\n",
      "Collecting googleapis-common-protos (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 7))\n",
      "Collecting zipp>=0.5 (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/b2/34/bfcb43cc0ba81f527bc4f40ef41ba2ff4080e047acb0586b56b3d017ace4/zipp-3.1.0-py3-none-any.whl\n",
      "Collecting pyasn1>=0.1.3 (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1))\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: grpcio\n",
      "  Running setup.py bdist_wheel for grpcio ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/ed/06/79/e559ab3b10134903b88e2df2df1b7cc4d3f1a92a46972a09fb\n",
      "Successfully built grpcio\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31msagemaker 1.44.0 has requirement requests<2.21,>=2.20.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrouge-score 0.0.3 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mpytorch-lightning 0.7.3 has requirement tqdm>=4.41.0, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: zipp, importlib-metadata, markdown, absl-py, setuptools, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, requests, grpcio, tensorboard-plugin-wit, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, tensorboard, keras-preprocessing, keras-applications, Keras, seqeval, portalocker, sacrebleu, rouge-score, termcolor, future, dill, promise, googleapis-common-protos, tensorflow-metadata, tensorflow-datasets, pytorch-lightning\n",
      "  Found existing installation: setuptools 39.1.0\n",
      "    Uninstalling setuptools-39.1.0:\n",
      "      Successfully uninstalled setuptools-39.1.0\n",
      "  Found existing installation: requests 2.20.0\n",
      "    Uninstalling requests-2.20.0:\n",
      "      Successfully uninstalled requests-2.20.0\n",
      "  Found existing installation: protobuf 3.5.2\n",
      "    Uninstalling protobuf-3.5.2:\n",
      "      Successfully uninstalled protobuf-3.5.2\n",
      "Successfully installed Keras-2.3.1 absl-py-0.9.0 cachetools-4.1.0 dill-0.3.1.1 future-0.18.2 google-auth-1.15.0 google-auth-oauthlib-0.4.1 googleapis-common-protos-1.51.0 grpcio-1.29.0 importlib-metadata-1.6.0 keras-applications-1.0.8 keras-preprocessing-1.1.2 markdown-3.2.2 oauthlib-3.1.0 portalocker-1.7.0 promise-2.3 protobuf-3.12.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 pytorch-lightning-0.7.3 requests-2.23.0 requests-oauthlib-1.3.0 rouge-score-0.0.3 rsa-4.0 sacrebleu-1.4.9 seqeval-0.0.12 setuptools-46.4.0 tensorboard-2.2.1 tensorboard-plugin-wit-1.6.0.post3 tensorflow-datasets-3.1.0 tensorflow-metadata-0.22.0 termcolor-1.1.0 zipp-3.1.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting ray==0.9.0.dev0 from https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "\u001b[?25l  Downloading https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl (21.7MB)\n",
      "\u001b[K    100% |████████████████████████████████| 21.7MB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp (from ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement not upgraded as not directly required: numpy>=1.16 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (1.16.4)\n",
      "Requirement not upgraded as not directly required: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (3.0.4)\n",
      "Requirement not upgraded as not directly required: protobuf>=3.8.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (3.12.1)\n",
      "Collecting py-spy>=0.2.0 (from ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl\n",
      "Requirement not upgraded as not directly required: msgpack<1.0.0,>=0.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (0.6.0)\n",
      "Requirement not upgraded as not directly required: colorama in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (0.3.9)\n",
      "Requirement not upgraded as not directly required: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (3.12)\n",
      "Requirement not upgraded as not directly required: jsonschema in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (2.6.0)\n",
      "Collecting redis<3.5.0,>=3.3.2 (from ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl\n",
      "Collecting google (from ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/81/51/36af1d18648574d13d8f43e863e95a97fe6f43d54a13fbcf272c638c10e9/google-2.0.3-py2.py3-none-any.whl\n",
      "Collecting click>=7.0 (from ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/3d/fa76db83bf75c4f8d338c2fd15c8d33fdd7ad23a9b5e57eb6c5de26b430e/click-7.1.2-py2.py3-none-any.whl\n",
      "Requirement not upgraded as not directly required: grpcio in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray==0.9.0.dev0) (1.29.0)\n",
      "Collecting async-timeout<4.0,>=3.0 (from aiohttp->ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
      "Collecting multidict<5.0,>=4.5 (from aiohttp->ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Requirement not upgraded as not directly required: typing-extensions>=3.6.5; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray==0.9.0.dev0) (3.7.4.1)\n",
      "Requirement not upgraded as not directly required: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray==0.9.0.dev0) (18.1.0)\n",
      "Requirement not upgraded as not directly required: chardet<4.0,>=2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray==0.9.0.dev0) (3.0.4)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->ray==0.9.0.dev0)\n",
      "  Using cached https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting idna-ssl>=1.0; python_version < \"3.7\" (from aiohttp->ray==0.9.0.dev0)\n",
      "Requirement not upgraded as not directly required: setuptools in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (46.4.0)\n",
      "Requirement not upgraded as not directly required: six>=1.9 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->ray==0.9.0.dev0) (1.11.0)\n",
      "Requirement not upgraded as not directly required: beautifulsoup4 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google->ray==0.9.0.dev0) (4.6.0)\n",
      "Requirement not upgraded as not directly required: idna>=2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from yarl<2.0,>=1.0->aiohttp->ray==0.9.0.dev0) (2.6)\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31msagemaker 1.44.0 has requirement requests<2.21,>=2.20.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrouge-score 0.0.3 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mpytorch-lightning 0.7.3 has requirement tqdm>=4.41.0, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: async-timeout, multidict, yarl, idna-ssl, aiohttp, py-spy, redis, google, click, ray\n",
      "  Found existing installation: click 6.7\n",
      "    Uninstalling click-6.7:\n",
      "      Successfully uninstalled click-6.7\n",
      "Successfully installed aiohttp-3.6.2 async-timeout-3.0.1 click-7.1.2 google-2.0.3 idna-ssl-1.1.0 multidict-4.7.6 py-spy-0.3.3 ray-0.9.0.dev0 redis-3.4.1 yarl-1.4.2\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: ray[tune] in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.9.0.dev0)\n",
      "Requirement already satisfied: grpcio in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (1.29.0)\n",
      "Requirement already satisfied: aiohttp in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (3.6.2)\n",
      "Requirement already satisfied: click>=7.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (7.1.2)\n",
      "Requirement already satisfied: jsonschema in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (2.6.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (3.12.1)\n",
      "Requirement already satisfied: redis<3.5.0,>=3.3.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (3.4.1)\n",
      "Requirement already satisfied: colorama in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (0.3.9)\n",
      "Requirement already satisfied: google in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (2.0.3)\n",
      "Requirement already satisfied: py-spy>=0.2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (0.3.3)\n",
      "Requirement already satisfied: filelock in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (3.0.4)\n",
      "Requirement already satisfied: pyyaml in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (3.12)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.6.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (0.6.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (1.16.4)\n",
      "Collecting tabulate; extra == \"tune\" (from ray[tune])\n",
      "  Using cached https://files.pythonhosted.org/packages/c4/f4/770ae9385990f5a19a91431163d262182d3203662ea2b5739d0fcfc080f1/tabulate-0.8.7-py3-none-any.whl\n",
      "Collecting tensorboardX; extra == \"tune\" (from ray[tune])\n",
      "  Using cached https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: pandas; extra == \"tune\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from ray[tune]) (0.24.2)\n",
      "Requirement already satisfied: six>=1.5.2 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from grpcio->ray[tune]) (1.11.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (1.4.2)\n",
      "Requirement already satisfied: idna-ssl>=1.0; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (1.1.0)\n",
      "Requirement already satisfied: multidict<5.0,>=4.5 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (4.7.6)\n",
      "Requirement already satisfied: async-timeout<4.0,>=3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (3.0.1)\n",
      "Requirement already satisfied: chardet<4.0,>=2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (3.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (18.1.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from aiohttp->ray[tune]) (3.7.4.1)\n",
      "Requirement already satisfied: setuptools in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from protobuf>=3.8.0->ray[tune]) (46.4.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from google->ray[tune]) (4.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2.7.3)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from pandas; extra == \"tune\"->ray[tune]) (2018.4)\n",
      "Requirement already satisfied: idna>=2.0 in /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from yarl<2.0,>=1.0->aiohttp->ray[tune]) (2.6)\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31msagemaker 1.44.0 has requirement requests<2.21,>=2.20.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrouge-score 0.0.3 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mpytorch-lightning 0.7.3 has requirement tqdm>=4.41.0, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: tabulate, tensorboardX\n",
      "Successfully installed tabulate-0.8.7 tensorboardX-2.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Cloning into 'apex'...\n",
      "remote: Enumerating objects: 6898, done.\u001b[K\n",
      "remote: Total 6898 (delta 0), reused 0 (delta 0), pack-reused 6898\u001b[K\n",
      "Receiving objects: 100% (6898/6898), 13.76 MiB | 31.04 MiB/s, done.\n",
      "Resolving deltas: 100% (4635/4635), done.\n",
      "Created temporary directory: /tmp/pip-ephem-wheel-cache-wx8weqyn\n",
      "Created temporary directory: /tmp/pip-install-brdzv6ax\n",
      "Processing /home/ubuntu/ray-e2e-nlp-example/apex\n",
      "  Created temporary directory: /tmp/pip-req-build-u1ulssas\n",
      "  Running setup.py (path:/tmp/pip-req-build-u1ulssas/setup.py) egg_info for package from file:///home/ubuntu/ray-e2e-nlp-example/apex\n",
      "    Running command python setup.py egg_info\n",
      "    torch.__version__  =  1.3.1\n",
      "    running egg_info\n",
      "    creating pip-egg-info/apex.egg-info\n",
      "    writing pip-egg-info/apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/apex.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'pip-egg-info/apex.egg-info/SOURCES.txt'\n",
      "  Source in /tmp/pip-req-build-u1ulssas has version 0.1, which satisfies requirement apex==0.1 from file:///home/ubuntu/ray-e2e-nlp-example/apex\n",
      "\u001b[31mfastai 1.0.59 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[31msagemaker 1.44.0 has requirement requests<2.21,>=2.20.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mrouge-score 0.0.3 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mpytorch-lightning 0.7.3 has requirement tqdm>=4.41.0, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: apex\n",
      "  Created temporary directory: /tmp/pip-record-gvzlrj2c\n",
      "  Running setup.py install for apex ... \u001b[?25l    Running command /home/ubuntu/anaconda3/envs/pytorch_p36/bin/python -u -c \"import setuptools, tokenize;__file__='/tmp/pip-req-build-u1ulssas/setup.py';f=getattr(tokenize, 'open', open)(__file__);code=f.read().replace('\\r\\n', '\\n');f.close();exec(compile(code, __file__, 'exec'))\" install --record /tmp/pip-record-gvzlrj2c/install-record.txt --single-version-externally-managed --compile\n",
      "    torch.__version__  =  1.3.1\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib\n",
      "    creating build/lib/apex\n",
      "    copying apex/__init__.py -> build/lib/apex\n",
      "    creating build/lib/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
      "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
      "    creating build/lib/apex/mlp\n",
      "    copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
      "    copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
      "    creating build/lib/apex/optimizers\n",
      "    copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
      "    copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
      "    copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
      "    copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
      "    copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
      "    copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
      "    creating build/lib/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
      "    copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
      "    copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
      "    copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
      "    creating build/lib/apex/reparameterization\n",
      "    copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
      "    copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
      "    copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
      "    creating build/lib/apex/parallel\n",
      "    copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
      "    copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
      "    creating build/lib/apex/normalization\n",
      "    copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
      "    copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
      "    creating build/lib/apex/contrib\n",
      "    copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
      "    creating build/lib/apex/RNN\n",
      "    copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
      "    copying apex/RNN/models.py -> build/lib/apex/RNN\n",
      "    copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
      "    copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
      "    creating build/lib/apex/pyprof\n",
      "    copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
      "    creating build/lib/apex/amp\n",
      "    copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
      "    copying apex/amp/compat.py -> build/lib/apex/amp\n",
      "    copying apex/amp/amp.py -> build/lib/apex/amp\n",
      "    copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
      "    copying apex/amp/utils.py -> build/lib/apex/amp\n",
      "    copying apex/amp/wrap.py -> build/lib/apex/amp\n",
      "    copying apex/amp/__init__.py -> build/lib/apex/amp\n",
      "    copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
      "    copying apex/amp/__version__.py -> build/lib/apex/amp\n",
      "    copying apex/amp/handle.py -> build/lib/apex/amp\n",
      "    copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
      "    copying apex/amp/scaler.py -> build/lib/apex/amp\n",
      "    copying apex/amp/frontend.py -> build/lib/apex/amp\n",
      "    copying apex/amp/opt.py -> build/lib/apex/amp\n",
      "    creating build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
      "    copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
      "    creating build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
      "    creating build/lib/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
      "    copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
      "    creating build/lib/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
      "    copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
      "    creating build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
      "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
      "    creating build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
      "    copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
      "    creating build/lib/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
      "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
      "    creating build/lib/apex/amp/lists\n",
      "    copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
      "    copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
      "    copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
      "    copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
      "    running install_lib\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
      "    copying build/lib/apex/multi_tensor_apply/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
      "    copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/multi_tensor_apply\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/mlp\n",
      "    copying build/lib/apex/mlp/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/mlp\n",
      "    copying build/lib/apex/mlp/mlp.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/mlp\n",
      "    copying build/lib/apex/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/fused_adagrad.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/fused_adam.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/fused_sgd.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/fused_novograd.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    copying build/lib/apex/optimizers/fused_lamb.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils\n",
      "    copying build/lib/apex/fp16_utils/fp16_optimizer.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils\n",
      "    copying build/lib/apex/fp16_utils/fp16util.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils\n",
      "    copying build/lib/apex/fp16_utils/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils\n",
      "    copying build/lib/apex/fp16_utils/loss_scaler.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization\n",
      "    copying build/lib/apex/reparameterization/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization\n",
      "    copying build/lib/apex/reparameterization/weight_norm.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization\n",
      "    copying build/lib/apex/reparameterization/reparameterization.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/distributed.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/multiproc.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/LARC.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    copying build/lib/apex/parallel/sync_batchnorm.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/normalization\n",
      "    copying build/lib/apex/normalization/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/normalization\n",
      "    copying build/lib/apex/normalization/fused_layer_norm.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/normalization\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib\n",
      "    copying build/lib/apex/contrib/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/fused_adam.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/fused_sgd.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    copying build/lib/apex/contrib/optimizers/fused_lamb.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/xentropy\n",
      "    copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/xentropy\n",
      "    copying build/lib/apex/contrib/xentropy/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/xentropy\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/groupbn\n",
      "    copying build/lib/apex/contrib/groupbn/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/groupbn\n",
      "    copying build/lib/apex/contrib/groupbn/batch_norm.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/groupbn\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN\n",
      "    copying build/lib/apex/RNN/cells.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN\n",
      "    copying build/lib/apex/RNN/models.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN\n",
      "    copying build/lib/apex/RNN/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN\n",
      "    copying build/lib/apex/RNN/RNNBackend.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/optim.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/embedding.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/utility.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/output.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/reduction.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/blas.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/data.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/prof.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/linear.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/randomSample.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/pooling.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/misc.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/pointwise.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/activation.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/base.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/__main__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/recurrentCell.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/loss.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/normalization.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/dropout.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/conv.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/softmax.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/convert.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/usage.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof\n",
      "    copying build/lib/apex/pyprof/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/db.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/kernel.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/nvvp.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/__main__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    copying build/lib/apex/pyprof/parse/parse.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
      "    copying build/lib/apex/pyprof/nvtx/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
      "    copying build/lib/apex/pyprof/nvtx/nvmarker.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/nvtx\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/_initialize.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/compat.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/amp.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/rnn_compat.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/utils.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/wrap.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/_process_optimizer.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/__version__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/handle.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/_amp_state.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/scaler.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    creating /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists\n",
      "    copying build/lib/apex/amp/lists/__init__.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists\n",
      "    copying build/lib/apex/amp/lists/tensor_overrides.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists\n",
      "    copying build/lib/apex/amp/lists/functional_overrides.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists\n",
      "    copying build/lib/apex/amp/lists/torch_overrides.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists\n",
      "    copying build/lib/apex/amp/frontend.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    copying build/lib/apex/amp/opt.py -> /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/multi_tensor_apply/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/multi_tensor_apply/multi_tensor_apply.py to multi_tensor_apply.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/mlp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/mlp/mlp.py to mlp.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/fused_adagrad.py to fused_adagrad.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/fused_novograd.py to fused_novograd.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils/fp16util.py to fp16util.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/fp16_utils/loss_scaler.py to loss_scaler.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization/weight_norm.py to weight_norm.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/reparameterization/reparameterization.py to reparameterization.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/distributed.py to distributed.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/multiproc.py to multiproc.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm_kernel.py to optimized_sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/optimized_sync_batchnorm.py to optimized_sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/sync_batchnorm_kernel.py to sync_batchnorm_kernel.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/LARC.py to LARC.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/parallel/sync_batchnorm.py to sync_batchnorm.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/normalization/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/normalization/fused_layer_norm.py to fused_layer_norm.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam.py to distributed_fused_adam.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/fp16_optimizer.py to fp16_optimizer.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam_v2.py to distributed_fused_adam_v2.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/distributed_fused_adam_v3.py to distributed_fused_adam_v3.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/fused_adam.py to fused_adam.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/fused_sgd.py to fused_sgd.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/optimizers/fused_lamb.py to fused_lamb.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py to fast_self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py to fast_encdec_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn.py to encdec_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/self_multihead_attn.py to self_multihead_attn.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py to fast_self_multihead_attn_norm_add_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/encdec_multihead_attn_func.py to encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/self_multihead_attn_func.py to self_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py to fast_encdec_multihead_attn_func.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/xentropy/softmax_xentropy.py to softmax_xentropy.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/xentropy/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/groupbn/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/contrib/groupbn/batch_norm.py to batch_norm.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN/cells.py to cells.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN/models.py to models.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/RNN/RNNBackend.py to RNNBackend.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/optim.py to optim.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/embedding.py to embedding.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/utility.py to utility.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/output.py to output.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/reduction.py to reduction.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/blas.py to blas.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/data.py to data.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/prof.py to prof.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/linear.py to linear.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/randomSample.py to randomSample.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/pooling.py to pooling.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/misc.py to misc.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/pointwise.py to pointwise.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/activation.py to activation.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/base.py to base.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/recurrentCell.py to recurrentCell.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/loss.py to loss.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/normalization.py to normalization.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/dropout.py to dropout.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/conv.py to conv.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/softmax.py to softmax.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/convert.py to convert.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/usage.py to usage.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/prof/index_slice_join_mutate.py to index_slice_join_mutate.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/db.py to db.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/kernel.py to kernel.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/nvvp.py to nvvp.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/__main__.py to __main__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/parse/parse.py to parse.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/nvtx/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/pyprof/nvtx/nvmarker.py to nvmarker.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/_initialize.py to _initialize.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/compat.py to compat.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/amp.py to amp.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/rnn_compat.py to rnn_compat.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/utils.py to utils.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/wrap.py to wrap.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/_process_optimizer.py to _process_optimizer.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/__version__.py to __version__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/handle.py to handle.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/_amp_state.py to _amp_state.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/scaler.py to scaler.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists/__init__.py to __init__.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists/tensor_overrides.py to tensor_overrides.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists/functional_overrides.py to functional_overrides.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/lists/torch_overrides.py to torch_overrides.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/frontend.py to frontend.cpython-36.pyc\n",
      "    byte-compiling /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex/amp/opt.py to opt.cpython-36.pyc\n",
      "    running install_egg_info\n",
      "    running egg_info\n",
      "    creating apex.egg-info\n",
      "    writing apex.egg-info/PKG-INFO\n",
      "    writing dependency_links to apex.egg-info/dependency_links.txt\n",
      "    writing top-level names to apex.egg-info/top_level.txt\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    reading manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    writing manifest file 'apex.egg-info/SOURCES.txt'\n",
      "    Copying apex.egg-info to /home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/apex-0.1-py3.6.egg-info\n",
      "    running install_scripts\n",
      "    writing list of installed files to '/tmp/pip-record-gvzlrj2c/install-record.txt'\n",
      "done\n",
      "\u001b[?25h  Removing source in /tmp/pip-req-build-u1ulssas\n",
      "Successfully installed apex-0.1\n",
      "Cleaning up...\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/huggingface/transformers\n",
    "!cd transformers && pip install . && pip install -r ./examples/requirements.txt\n",
    "!pip install -U https://s3-us-west-2.amazonaws.com/ray-wheels/latest/ray-0.9.0.dev0-cp36-cp36m-manylinux1_x86_64.whl\n",
    "!pip install ray[tune]\n",
    "!git clone https://github.com/NVIDIA/apex; cd apex && pip install -v --no-cache-dir  ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py && python download_glue_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 21 17:45:46 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 418.87.01    Driver Version: 418.87.01    CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   44C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   42C    P0    39W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   43C    P0    41W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   44C    P0    41W / 300W |      0MiB / 16130MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import some libraries we need for the example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from filelock import FileLock\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import (DataLoader, RandomSampler, \n",
    "                              SequentialSampler, TensorDataset)\n",
    "from tqdm import trange\n",
    "import torch.distributed as dist\n",
    "\n",
    "from transformers import (AdamW,\n",
    "                          AutoConfig, AutoModelForSequenceClassification,\n",
    "                          AutoTokenizer, get_linear_schedule_with_warmup,\n",
    "                          HfArgumentParser, TrainingArguments)\n",
    "from transformers import glue_output_modes as output_modes\n",
    "from transformers import glue_processors as processors\n",
    "from transformers import (glue_convert_examples_to_features as\n",
    "                          convert_examples_to_features)\n",
    "\n",
    "import ray\n",
    "from ray.util.sgd.torch import TrainingOperator\n",
    "from ray.util.sgd import TorchTrainer\n",
    "\n",
    "try:\n",
    "    from apex import amp\n",
    "except ImportError:\n",
    "    amp = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we set some configuration arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(adam_epsilon=1e-08, address='auto', cache_dir=None, config_name=None, data_dir='glue_data/RTE/', do_eval=True, do_predict=False, do_train=True, evaluate_during_training=False, fp16=True, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=2e-05, local_rank=-1, logging_dir=None, logging_first_step=False, logging_steps=500, max_grad_norm=1.0, max_seq_length=128, max_steps=-1, model_name_or_path='bert-base-cased', model_type='bert', no_cuda=False, num_train_epochs=3, num_workers=8, output_dir='output_dir/', output_mode='classification', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=8, per_gpu_train_batch_size=8, save_steps=500, save_total_limit=None, seed=42, task_name='rte', tokenizer_name=None, tpu_metrics_debug=False, tpu_num_cores=None, warmup_steps=0, weight_decay=0.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training arguments (from hugging face)\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir = \"output_dir/\",\n",
    "    learning_rate = 2e-5,\n",
    "    num_train_epochs = 3,\n",
    "    per_gpu_train_batch_size = 8,\n",
    "    fp16 = True,\n",
    "    do_train = True,\n",
    "    do_eval = True\n",
    ")\n",
    "args = argparse.Namespace(**vars(training_arguments))\n",
    "\n",
    "# Model arguments\n",
    "args.model_name_or_path = \"bert-base-cased\"\n",
    "args.model_type = \"bert\"\n",
    "args.config_name = None\n",
    "args.tokenizer_name = None\n",
    "args.cache_dir = None\n",
    "\n",
    "# Data processing arguments\n",
    "args.task_name = \"RTE\"\n",
    "args.data_dir = \"glue_data/RTE/\"\n",
    "args.max_seq_length = 128\n",
    "args.overwrite_cache = False\n",
    "\n",
    "# Ray arguments\n",
    "args.num_workers = 8\n",
    "args.address = \"auto\"\n",
    "\n",
    "use_gpu = torch.cuda.is_available() and not args.no_cuda\n",
    "\n",
    "# GLUE task preparation\n",
    "args.task_name = args.task_name.lower()\n",
    "assert args.task_name in processors\n",
    "args.output_mode = output_modes[args.task_name]\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we connect to the ray server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '172.31.17.18',\n",
       " 'raylet_ip_address': '172.31.17.18',\n",
       " 'redis_address': '172.31.17.18:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-05-21_17-45-08_202298_97701/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-05-21_17-45-08_202298_97701/sockets/raylet',\n",
       " 'webui_url': 'localhost:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-05-21_17-45-08_202298_97701'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init(address=args.address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define several helper functions for Torch trainer. First we define the data creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, task, tokenizer, evaluate=False):\n",
    "    processor = processors[task]()\n",
    "    output_mode = output_modes[task]\n",
    "    # Load data features from cache or dataset file\n",
    "    cached_features_file = os.path.join(\n",
    "        args.data_dir,\n",
    "        \"cached_{}_{}_{}_{}\".format(\n",
    "            \"dev\" if evaluate else \"train\",\n",
    "            list(filter(None, args.model_name_or_path.split(\"/\"))).pop(),\n",
    "            str(args.max_seq_length),\n",
    "            str(task),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    with FileLock(\"/tmp/load_and_cache_examples.lock\"):\n",
    "        if os.path.exists(cached_features_file) and not args.overwrite_cache:\n",
    "            print(\"Loading features from cached file %s\",\n",
    "                  cached_features_file)\n",
    "            features = torch.load(cached_features_file)\n",
    "        else:\n",
    "            print(\"Creating features from dataset file at %s\",\n",
    "                  args.data_dir)\n",
    "            label_list = processor.get_labels()\n",
    "            if task in [\"mnli\", \"mnli-mm\"\n",
    "                        ] and args.model_type in [\"roberta\", \"xlmroberta\"]:\n",
    "                # HACK(label indices are swapped in RoBERTa pretrained model)\n",
    "                label_list[1], label_list[2] = label_list[2], label_list[1]\n",
    "            examples = (processor.get_dev_examples(args.data_dir) if evaluate\n",
    "                        else processor.get_train_examples(args.data_dir))\n",
    "            features = convert_examples_to_features(\n",
    "                examples,\n",
    "                tokenizer,\n",
    "                label_list=label_list,\n",
    "                max_length=args.max_seq_length,\n",
    "                output_mode=output_mode,\n",
    "            )\n",
    "            if not os.path.exists(cached_features_file):\n",
    "                print(\"Saving features into cached file %s\",\n",
    "                      cached_features_file)\n",
    "                torch.save(features, cached_features_file)\n",
    "\n",
    "    # Convert to Tensors and build dataset\n",
    "    all_input_ids = torch.tensor(\n",
    "        [f.input_ids for f in features], dtype=torch.long)\n",
    "    all_attention_mask = torch.tensor(\n",
    "        [f.attention_mask for f in features], dtype=torch.long)\n",
    "    all_token_type_ids = torch.tensor(\n",
    "        [f.token_type_ids for f in features], dtype=torch.long)\n",
    "    if output_mode == \"classification\":\n",
    "        all_labels = torch.tensor(\n",
    "            [f.label for f in features], dtype=torch.long)\n",
    "    elif output_mode == \"regression\":\n",
    "        all_labels = torch.tensor(\n",
    "            [f.label for f in features], dtype=torch.float)\n",
    "\n",
    "    dataset = TensorDataset(all_input_ids, all_attention_mask,\n",
    "                            all_token_type_ids, all_labels)\n",
    "    return dataset\n",
    "\n",
    "def data_creator(config):\n",
    "    args = config[\"args\"]\n",
    "    start = time.time()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        args.tokenizer_name\n",
    "        if args.tokenizer_name else args.model_name_or_path,\n",
    "        cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "    )\n",
    "    print(\"tokenizer instantiation time: {}\".format(time.time() - start))\n",
    "\n",
    "    train_dataset = load_and_cache_examples(\n",
    "        args, args.task_name, tokenizer, evaluate=False)\n",
    "    train_sampler = RandomSampler(\n",
    "        train_dataset) if not dist.is_initialized() else None\n",
    "    return DataLoader(\n",
    "        train_dataset,\n",
    "        sampler=train_sampler,\n",
    "        batch_size=args.per_gpu_train_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the model creator for the Torch trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_creator(config):\n",
    "    with FileLock(os.path.expanduser(\"~/.download.lock\")):\n",
    "        args = config[\"args\"]\n",
    "        processor = processors[args.task_name]()\n",
    "        label_list = processor.get_labels()\n",
    "        num_labels = len(label_list)\n",
    "        config = AutoConfig.from_pretrained(\n",
    "            args.config_name if args.config_name else args.model_name_or_path,\n",
    "            num_labels=num_labels,\n",
    "            finetuning_task=args.task_name,\n",
    "            cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "        )\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            args.model_name_or_path,\n",
    "            from_tf=bool(\".ckpt\" in args.model_name_or_path),\n",
    "            config=config,\n",
    "            cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "        )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_creator(model, config):\n",
    "    args = config[\"args\"]\n",
    "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in model.named_parameters()\n",
    "                if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": args.weight_decay,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in model.named_parameters()\n",
    "                if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay\": 0.0\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    return AdamW(\n",
    "        optimizer_grouped_parameters,\n",
    "        lr=args.learning_rate,\n",
    "        eps=args.adam_epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the training operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def announce_training(args, dataset_len, t_total):\n",
    "    # Train!\n",
    "    print(\"***** Running training *****\")\n",
    "    print(\"  Num examples = %d\", dataset_len)\n",
    "    print(\"  Num Epochs = %d\", args.num_train_epochs)\n",
    "    print(\"  Instantaneous batch size per GPU = %d\",\n",
    "          args.per_gpu_train_batch_size)\n",
    "    print(\n",
    "        \"  Total train batch size (w. parallel, distributed & accum) = %d\",\n",
    "        args.per_gpu_train_batch_size * args.gradient_accumulation_steps *\n",
    "        args.num_workers,\n",
    "    )\n",
    "    print(\"  Gradient Accumulation steps = %d\",\n",
    "          args.gradient_accumulation_steps)\n",
    "    print(\"  Total optimization steps = %d\", t_total)\n",
    "\n",
    "\n",
    "class TransformerOperator(TrainingOperator):\n",
    "    def setup(self, config):\n",
    "        self.args = args = config[\"args\"]\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            args.tokenizer_name\n",
    "            if args.tokenizer_name else args.model_name_or_path,\n",
    "            cache_dir=args.cache_dir if args.cache_dir else None,\n",
    "        )\n",
    "\n",
    "        self.train_data_len = len(self.train_loader)\n",
    "        self._warmup_scheduler = get_linear_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=args.warmup_steps,\n",
    "            num_training_steps=self.calculate_t_total())\n",
    "        self._global_step = 0\n",
    "\n",
    "        announce_training(args, self.train_data_len, self.calculate_t_total())\n",
    "\n",
    "    def train_batch(self, batch, batch_info=None):\n",
    "        args = self.args\n",
    "        model = self.model\n",
    "        optimizer = self.optimizer\n",
    "        step = batch_info[\"batch_idx\"]\n",
    "\n",
    "        model.train()\n",
    "        batch = tuple(t.to(self.device) for t in batch)\n",
    "        inputs = {\n",
    "            \"input_ids\": batch[0],\n",
    "            \"attention_mask\": batch[1],\n",
    "            \"labels\": batch[3]\n",
    "        }\n",
    "        if args.model_type != \"distilbert\":\n",
    "            # XLM, DistilBERT, RoBERTa, and XLM-RoBERTa don't use segment_ids\n",
    "            inputs[\"token_type_ids\"] = (batch[2] if args.model_type in [\n",
    "                \"bert\", \"xlnet\", \"albert\"\n",
    "            ] else None)\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "        # model outputs are always tuple in transformers (see doc)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if args.gradient_accumulation_steps > 1:\n",
    "            loss = loss / args.gradient_accumulation_steps\n",
    "\n",
    "        if args.fp16:\n",
    "            with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "                scaled_loss.backward()\n",
    "        else:\n",
    "            loss.backward()\n",
    "\n",
    "        batch_loss = loss.item()\n",
    "\n",
    "        # last step in epoch but step is always smaller\n",
    "        # than gradient_accumulation_steps\n",
    "        ending = (self.train_data_len <= args.gradient_accumulation_steps\n",
    "                  and (step + 1) == self.train_data_len)\n",
    "        if (step + 1) % args.gradient_accumulation_steps == 0 or ending:\n",
    "            if args.fp16:\n",
    "                torch.nn.utils.clip_grad_norm_(\n",
    "                    amp.master_params(optimizer), args.max_grad_norm)\n",
    "            else:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),\n",
    "                                               args.max_grad_norm)\n",
    "\n",
    "            self.optimizer.step()\n",
    "            self._warmup_scheduler.step()  # Update learning rate schedule\n",
    "            model.zero_grad()\n",
    "            self._global_step += 1\n",
    "\n",
    "        learning_rate_scalar = self._warmup_scheduler.get_lr()[0]\n",
    "        return {\"learning_rate\": learning_rate_scalar, \"loss\": batch_loss}\n",
    "\n",
    "    def calculate_t_total(self):\n",
    "        args = self.args\n",
    "        grad_accum_steps = args.gradient_accumulation_steps\n",
    "        train_data_len = len(self.train_loader)\n",
    "        if args.max_steps > 0:\n",
    "            t_total = args.max_steps\n",
    "            args.num_train_epochs = args.max_steps // (\n",
    "                train_data_len // grad_accum_steps) + 1\n",
    "        else:\n",
    "            t_total = (\n",
    "                train_data_len // grad_accum_steps * args.num_train_epochs)\n",
    "        return t_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.cuda' has no attribute 'is_initialized'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-4164bb055bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0muse_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0muse_tqdm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         config={\"args\": args})\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_creator, data_creator, optimizer_creator, loss_creator, scheduler_creator, training_operator_cls, initialization_hook, config, num_workers, use_gpu, backend, wrap_ddp, serialize_data_creation, use_fp16, use_tqdm, apex_args, add_dist_sampler, scheduler_step_freq, num_replicas, batch_size, data_loader_args)\u001b[0m\n\u001b[1;32m    272\u001b[0m                         \"address='auto')` before instantiating the Trainer.\")\n\u001b[1;32m    273\u001b[0m             \u001b[0mray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_workers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_replicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_configure_and_split_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/util/sgd/torch/torch_trainer.py\u001b[0m in \u001b[0;36m_start_workers\u001b[0;34m(self, num_workers)\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;31m# Start local worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m             self.local_worker = LocalDistributedRunner(\n\u001b[0;32m--> 332\u001b[0;31m                 num_cpus=1, num_gpus=int(self.use_gpu), **params)\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m             \u001b[0;31m# Generate actor class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/util/sgd/torch/distributed_torch_runner.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, num_cpus, num_gpus, *args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_actor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnum_gpus\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_reserve_and_set_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocalDistributedRunner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/util/sgd/torch/distributed_torch_runner.py\u001b[0m in \u001b[0;36m_try_reserve_and_set_cuda\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_reserve_and_set_cuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0muse_found_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA_VISIBLE_DEVICES\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                            \u001b[0;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreserve_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;31m# This needs to be set even if torch.cuda is already\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.cuda' has no attribute 'is_initialized'"
     ]
    }
   ],
   "source": [
    "trainer = TorchTrainer(\n",
    "        model_creator=model_creator,\n",
    "        data_creator=data_creator,\n",
    "        optimizer_creator=optimizer_creator,\n",
    "        training_operator_cls=TransformerOperator,\n",
    "        use_fp16=args.fp16,\n",
    "        apex_args={\"opt_level\": args.fp16_opt_level},\n",
    "        num_workers=args.num_workers,\n",
    "        use_gpu=use_gpu,\n",
    "        use_tqdm=True,\n",
    "        config={\"args\": args})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.3.1'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-21 17:47:20,307\tWARNING worker.py:1093 -- Authentication failed with an error: HTTPConnectionPool(host='dashboard.ray.io', port=9081): Max retries exceeded with url: /auth (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f70cc458198>: Failed to establish a new connection: [Errno 110] Connection timed out',))\n",
      "Traceback: Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 171, in _new_conn\n",
      "    (self._dns_host, self.port), self.timeout, **extra_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/util/connection.py\", line 79, in create_connection\n",
      "    raise err\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/util/connection.py\", line 69, in create_connection\n",
      "    sock.connect(sa)\n",
      "TimeoutError: [Errno 110] Connection timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 600, in urlopen\n",
      "    chunked=chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 354, in _make_request\n",
      "    conn.request(method, url, **httplib_request_kw)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/http/client.py\", line 1239, in request\n",
      "    self._send_request(method, url, body, headers, encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/http/client.py\", line 1285, in _send_request\n",
      "    self.endheaders(body, encode_chunked=encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/http/client.py\", line 1234, in endheaders\n",
      "    self._send_output(message_body, encode_chunked=encode_chunked)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/http/client.py\", line 1026, in _send_output\n",
      "    self.send(msg)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/http/client.py\", line 964, in send\n",
      "    self.connect()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 196, in connect\n",
      "    conn = self._new_conn()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connection.py\", line 180, in _new_conn\n",
      "    self, \"Failed to establish a new connection: %s\" % e)\n",
      "urllib3.exceptions.NewConnectionError: <urllib3.connection.HTTPConnection object at 0x7f70cc458198>: Failed to establish a new connection: [Errno 110] Connection timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/adapters.py\", line 449, in send\n",
      "    timeout=timeout\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/connectionpool.py\", line 638, in urlopen\n",
      "    _stacktrace=sys.exc_info()[2])\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/urllib3/util/retry.py\", line 398, in increment\n",
      "    raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.MaxRetryError: HTTPConnectionPool(host='dashboard.ray.io', port=9081): Max retries exceeded with url: /auth (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f70cc458198>: Failed to establish a new connection: [Errno 110] Connection timed out',))\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/dashboard/metrics_exporter/client.py\", line 77, in start_exporting_metrics\n",
      "    self._authenticate()\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/dashboard/metrics_exporter/client.py\", line 48, in _authenticate\n",
      "    self.dashboard_id)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/ray/dashboard/metrics_exporter/api.py\", line 16, in authentication_request\n",
      "    response = requests.post(url, data=auth_requeset.json())\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/api.py\", line 119, in post\n",
      "    return request('post', url, data=data, json=json, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/requests/adapters.py\", line 516, in send\n",
      "    raise ConnectionError(e, request=request)\n",
      "requests.exceptions.ConnectionError: HTTPConnectionPool(host='dashboard.ray.io', port=9081): Max retries exceeded with url: /auth (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7f70cc458198>: Failed to establish a new connection: [Errno 110] Connection timed out',))\n",
      " Please reenable the metrics export by going to the url: localhost:8265/api/metrics/enable\n"
     ]
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_pytorch_p36)",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
